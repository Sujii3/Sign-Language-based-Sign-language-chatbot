# Sign-Language-based-Sign-language-chatbot
Created a responsive machine learning model that is trained and can understand different hand symbols and be able to create a sentence through the sign language inputs of the user. Sending this input to a NLP-based chatbot that retrieves data using APIs.

Handgesture.ipynb main file with all the code in Jupyter Notebook format.

Action.h5 from 0 to 4 are different models that were trained using Tensorflow Keras
MP_DATA stores the Numpy arrays of all the Mediapipe movements to get access while training.

The PPT explains the overall of project and the Main Pdf document explains the details and flow of the project.

